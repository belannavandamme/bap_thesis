{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import most important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import V-dem dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belan\\AppData\\Local\\Temp\\ipykernel_51916\\2069364999.py:5: DtypeWarning: Columns (364,365,366,399,415,804,836,837,924,1240,1257,1486,3094,3168,3169,3341,3342,3344,3345,3347,3350,3352) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  vdem_data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country_name country_text_id  country_id  year historical_date  project  \\\n",
      "0       Mexico             MEX           3  1789      1789-12-31        1   \n",
      "1       Mexico             MEX           3  1790      1790-12-31        1   \n",
      "2       Mexico             MEX           3  1791      1791-12-31        1   \n",
      "3       Mexico             MEX           3  1792      1792-12-31        1   \n",
      "4       Mexico             MEX           3  1793      1793-12-31        1   \n",
      "\n",
      "   historical                  histname  codingstart  codingend  ...  \\\n",
      "0           1  Viceroyalty of New Spain         1789       2023  ...   \n",
      "1           1  Viceroyalty of New Spain         1789       2023  ...   \n",
      "2           1  Viceroyalty of New Spain         1789       2023  ...   \n",
      "3           1  Viceroyalty of New Spain         1789       2023  ...   \n",
      "4           1  Viceroyalty of New Spain         1789       2023  ...   \n",
      "\n",
      "   e_mipopula  e_miurbani  e_pefeliex  e_wb_pop  e_pechmor  e_miinteco  \\\n",
      "0         NaN         NaN         NaN       NaN        NaN         0.0   \n",
      "1         NaN         NaN         NaN       NaN        NaN         0.0   \n",
      "2         NaN         NaN         NaN       NaN        NaN         0.0   \n",
      "3         NaN         NaN         NaN       NaN        NaN         0.0   \n",
      "4         NaN         NaN         NaN       NaN        NaN         0.0   \n",
      "\n",
      "   e_civil_war  e_miinterc  e_pt_coup  e_pt_coup_attempts  \n",
      "0          NaN         0.0        NaN                 NaN  \n",
      "1          NaN         0.0        NaN                 NaN  \n",
      "2          NaN         0.0        NaN                 NaN  \n",
      "3          NaN         0.0        NaN                 NaN  \n",
      "4          NaN         0.0        NaN                 NaN  \n",
      "\n",
      "[5 rows x 4607 columns]\n"
     ]
    }
   ],
   "source": [
    "# Provide the full path to the file\n",
    "file_path = r\"C:\\Users\\belan\\bap_thesis\\data\\V-Dem_data_folder\\V-Dem-CY-Full+Others-v14.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "vdem_data = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows\n",
    "print(vdem_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIlter years, every year before 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years only kept from 2002 and onwards\n",
    "vdem_data = vdem_data[vdem_data['year'] >= 2002]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter V-dem countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    country_name country_text_id  country_id  year historical_date  project  \\\n",
      "572       Sweden             SWE           5  2002      2002-12-31        0   \n",
      "573       Sweden             SWE           5  2003      2003-12-31        0   \n",
      "574       Sweden             SWE           5  2004      2004-12-31        0   \n",
      "575       Sweden             SWE           5  2005      2005-12-31        0   \n",
      "576       Sweden             SWE           5  2006      2006-12-31        0   \n",
      "\n",
      "     historical           histname  codingstart  codingend  ...  e_mipopula  \\\n",
      "572           1  Kingdom of Sweden         1789       2023  ...         NaN   \n",
      "573           1  Kingdom of Sweden         1789       2023  ...         NaN   \n",
      "574           1  Kingdom of Sweden         1789       2023  ...         NaN   \n",
      "575           1  Kingdom of Sweden         1789       2023  ...         NaN   \n",
      "576           1  Kingdom of Sweden         1789       2023  ...         NaN   \n",
      "\n",
      "     e_miurbani  e_pefeliex   e_wb_pop  e_pechmor  e_miinteco  e_civil_war  \\\n",
      "572         NaN         NaN  8924958.0       3.99         NaN          0.0   \n",
      "573         NaN         NaN  8958229.0       3.88         NaN          0.0   \n",
      "574         NaN         NaN  8993531.0       3.75         NaN          0.0   \n",
      "575         NaN         NaN  9029572.0       3.60         NaN          0.0   \n",
      "576         NaN         NaN  9080505.0       3.45         NaN          0.0   \n",
      "\n",
      "     e_miinterc  e_pt_coup  e_pt_coup_attempts  \n",
      "572         NaN        0.0                 0.0  \n",
      "573         NaN        0.0                 0.0  \n",
      "574         NaN        0.0                 0.0  \n",
      "575         NaN        0.0                 0.0  \n",
      "576         NaN        0.0                 0.0  \n",
      "\n",
      "[5 rows x 4607 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the list of countries you want to keep\n",
    "countries_to_keep = [\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\",\n",
    " \"Czech Republic\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \n",
    " \"Greece\", \"Iceland\", \"Ireland\", \"Italy\", \"Israel\", \"Latvia\", \"Lithuania\", \n",
    " \"Luxembourg\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \n",
    " \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\", \"United Kingdom\"]  \n",
    "\n",
    "# Filter the dataset\n",
    "filtered_data = vdem_data[vdem_data['country_name'].isin(countries_to_keep)]\n",
    "\n",
    "# Check the result\n",
    "print(filtered_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the filtered data to a new file\n",
    "filtered_data.to_csv(r\"C:\\Users\\belan\\bap_thesis\\data\\filtered_V-Dem_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belan\\AppData\\Local\\Temp\\ipykernel_51916\\2606764764.py:4: DtypeWarning: Columns (52,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ess_data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name  essround  edition    proddate  idno cntry  dweight   pspwght  \\\n",
      "0  ESS1e06_7         1      6.7  23.11.2023     1    AT   0.9452  0.940933   \n",
      "1  ESS1e06_7         1      6.7  23.11.2023     2    AT   0.4726  0.470466   \n",
      "2  ESS1e06_7         1      6.7  23.11.2023     3    AT   0.9452  1.392155   \n",
      "3  ESS1e06_7         1      6.7  23.11.2023     4    AT   0.9452  1.382163   \n",
      "4  ESS1e06_7         1      6.7  23.11.2023     6    AT   1.8905  1.437766   \n",
      "\n",
      "    pweight  anweight  ...  eduil2  eduail2  edupl2  eduyrpl  edugb1  eduagb1  \\\n",
      "0  0.271487  0.255451  ...     NaN      NaN     NaN      NaN     NaN      NaN   \n",
      "1  0.271487  0.127726  ...     NaN      NaN     NaN      NaN     NaN      NaN   \n",
      "2  0.271487  0.377953  ...     NaN      NaN     NaN      NaN     NaN      NaN   \n",
      "3  0.271487  0.375240  ...     NaN      NaN     NaN      NaN     NaN      NaN   \n",
      "4  0.271487  0.390336  ...     NaN      NaN     NaN      NaN     NaN      NaN   \n",
      "\n",
      "   edubgb1  educgb1  edlvdrs  edlvdme  \n",
      "0      NaN      NaN      NaN      NaN  \n",
      "1      NaN      NaN      NaN      NaN  \n",
      "2      NaN      NaN      NaN      NaN  \n",
      "3      NaN      NaN      NaN      NaN  \n",
      "4      NaN      NaN      NaN      NaN  \n",
      "\n",
      "[5 rows x 204 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\belan\\bap_thesis\\data\\ESS_data_folder\\ESS_combined_dataset.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "ess_data = pd.read_csv(file_path)\n",
    "\n",
    "# Check the first few rows\n",
    "print(ess_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of all the Educatation data because too much to make numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "relevant_columns = [\"name\", \"essround\", \"edition\", \"idno\", \"cntry\", \"dweight\",\n",
    "\"pspwght\", \"pweight\", \"anweight\", \"prob\", \"stratum\", \"psu\",\"netuse\", \"netusoft\", \"netustm\",\n",
    "\"nwspol\", \"nwsppol\", \"nwsptot\", \"pplfair\", \"pplhlp\", \"ppltrst\", \"rdpol\", \"rdtot\",\n",
    "\"tvpol\", \"tvtot\", \"cptppol\", \"cptppola\", \"dmcntov\", \"etapapl\", \"lrscale\", \"polcmpl\",\n",
    "\"polintr\", \"psppipl\", \"psppipla\", \"psppsgv\", \"psppsgva\", \"ptcpplt\", \"stfdem\", \"stfeco\",\n",
    "\"stfgov\", \"trstep\", \"trstlgl\", \"trstplc\", \"trstplt\", \"trstprl\", \"trstprt\",\"trstun\",\n",
    "\"vote\", \"loylead\"\n",
    "]\n",
    "\n",
    "ess_reduced = ess_data[relevant_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use version to create a new column with the year\n",
    "# Map ESS `name` to the corresponding year\n",
    "ess_name_to_year = {\n",
    "    'ESS1e06_7': 2002,\n",
    "    'ESS2e03_6': 2004,\n",
    "    'ESS3e03_7': 2006,\n",
    "    'ESS4e04_6': 2008,\n",
    "    'ESS5e03_5': 2010,\n",
    "    'ESS6e02_6': 2012,\n",
    "    'ESS7e02_3': 2014,\n",
    "    'ESS8e02_3': 2016,\n",
    "    'ESS9e03_2': 2018,\n",
    "    'ESS10e03_2': 2020,\n",
    "    'ESS11e02': 2023,\n",
    "}\n",
    "\n",
    "# Add a year column to ESS data\n",
    "ess_data['year'] = ess_data['name'].map(ess_name_to_year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ESS `cntry` codes to country names\n",
    "ess_country_mapping = {\n",
    "    \"AL\": \"Albania\",\n",
    "    \"AT\": \"Austria\",\n",
    "    \"BE\": \"Belgium\",\n",
    "    \"BG\": \"Bulgaria\",\n",
    "    \"CH\": \"Switzerland\",\n",
    "    \"CY\": \"Cyprus\",\n",
    "    \"CZ\": \"Czech Republic\",\n",
    "    \"DE\": \"Germany\",\n",
    "    \"DK\": \"Denmark\",\n",
    "    \"EE\": \"Estonia\",\n",
    "    \"ES\": \"Spain\",\n",
    "    \"FI\": \"Finland\",\n",
    "    \"FR\": \"France\",\n",
    "    \"GB\": \"United Kingdom\",\n",
    "    \"GE\": \"Georgia\",  # Not in `countries_to_keep`\n",
    "    \"GR\": \"Greece\",\n",
    "    \"HR\": \"Croatia\",\n",
    "    \"HU\": \"Hungary\",\n",
    "    \"IE\": \"Ireland\",\n",
    "    \"IS\": \"Iceland\",\n",
    "    \"IL\": \"Israel\",\n",
    "    \"IT\": \"Italy\",\n",
    "    \"LT\": \"Lithuania\",\n",
    "    \"LU\": \"Luxembourg\",\n",
    "    \"LV\": \"Latvia\",\n",
    "    \"ME\": \"Montenegro\",  # Not in `countries_to_keep`\n",
    "    \"MK\": \"North Macedonia\",  # Not in `countries_to_keep`\n",
    "    \"NL\": \"Netherlands\",\n",
    "    \"NO\": \"Norway\",\n",
    "    \"PL\": \"Poland\",\n",
    "    \"PT\": \"Portugal\",\n",
    "    \"RO\": \"Romania\",\n",
    "    \"RS\": \"Serbia\",  # Not in `countries_to_keep`\n",
    "    \"RU\": \"Russian Federation\",  # Not in `countries_to_keep`\n",
    "    \"SE\": \"Sweden\",\n",
    "    \"SI\": \"Slovenia\",\n",
    "    \"SK\": \"Slovakia\",\n",
    "    \"TR\": \"Turkey\",  # Not in `countries_to_keep`\n",
    "    \"UA\": \"Ukraine\",  # Not in `countries_to_keep`\n",
    "    \"XK\": \"Kosovo\",  # Not in `countries_to_keep`\n",
    "}\n",
    "\n",
    "# replace the country codes with the country names\n",
    "if 'cntry' in ess_data.columns:\n",
    "    ess_data['country'] = ess_data['cntry'].map(ess_country_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for relevant countries if needed\n",
    "countries_to_keep = [\n",
    "    \"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
    "    \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Iceland\",\n",
    "    \"Ireland\", \"Italy\", \"Israel\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \n",
    "    \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Slovakia\", \n",
    "    \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\", \"United Kingdom\"\n",
    "]\n",
    "ess_data = ess_data[ess_data['country'].isin(countries_to_keep)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform all the variables\n",
    "start with net use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special missing values for continuous variables\n",
    "ess_reduced['netustm_cleaned'] = ess_reduced['netustm'].replace({6666: None, 7777: None, 8888: None, 9999: None})\n",
    "ess_reduced['nwspol_cleaned'] = ess_reduced['nwspol'].replace({7777: None, 8888: None, 9999: None})\n",
    "\n",
    "# Map ordinal variables to continuous equivalents\n",
    "netuse_mapping = {0: 0, 1: 0, 2: 0.25, 3: 0.5, 4: 1, 5: 2, 6: 4, 7: 7, 77: None, 88: None, 99: None}\n",
    "netusoft_mapping = {1: 0, 2: 1, 3: 3, 4: 5, 5: 7, 7: None, 8: None, 9: None}\n",
    "nwsppol_mapping = {0: 0, 1: 0.25, 2: 0.75, 3: 1.25, 4: 1.75, 5: 2.25, 6: 2.75, 7: 3.5, 66: None, 77: None, 88: None, 99: None}\n",
    "nwsptot_mapping = nwsppol_mapping  # Same mapping as nwsppol\n",
    "\n",
    "ess_reduced['netuse_continuous'] = ess_reduced['netuse'].map(netuse_mapping)\n",
    "ess_reduced['netusoft_continuous'] = ess_reduced['netusoft'].map(netusoft_mapping)\n",
    "ess_reduced['nwsppol_continuous'] = ess_reduced['nwsppol'].map(nwsppol_mapping)\n",
    "ess_reduced['nwsptot_continuous'] = ess_reduced['nwsptot'].map(nwsptot_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   netuse_continuous  netusoft_continuous netustm_cleaned nwspol_cleaned  \\\n",
      "0                2.0                  NaN             NaN            NaN   \n",
      "1                4.0                  NaN             NaN            NaN   \n",
      "2                0.0                  NaN             NaN            NaN   \n",
      "3                1.0                  NaN             NaN            NaN   \n",
      "4                7.0                  NaN             NaN            NaN   \n",
      "\n",
      "   nwsppol_continuous  nwsptot_continuous  \n",
      "0                0.25                0.25  \n",
      "1                0.75                0.75  \n",
      "2                 NaN                0.00  \n",
      "3                0.75                0.75  \n",
      "4                 NaN                0.00  \n"
     ]
    }
   ],
   "source": [
    "# verify output\n",
    "print(ess_reduced[['netuse_continuous', 'netusoft_continuous', 'netustm_cleaned', 'nwspol_cleaned', 'nwsppol_continuous', 'nwsptot_continuous']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trust in average person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all ordinal variables, so only cleaned and checked for missing values\n",
    "# Clean 'pplfair' (most people try to take advantage vs. fair)\n",
    "# Special values (77: Refusal, 88: Don't know, 99: No answer) are treated as missing (None)\n",
    "ess_reduced['pplfair_cleaned'] = ess_reduced['pplfair'].replace({\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None   # No answer\n",
    "})\n",
    "\n",
    "# Clean 'pplhlp' (people mostly helpful vs. looking out for themselves)\n",
    "ess_reduced['pplhlp_cleaned'] = ess_reduced['pplhlp'].replace({\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None   # No answer\n",
    "})\n",
    "\n",
    "# Clean 'ppltrst' (most people can be trusted vs. you can't be too careful)\n",
    "ess_reduced['ppltrst_cleaned'] = ess_reduced['ppltrst'].replace({\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None   # No answer\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530711 entries, 0 to 530710\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   pplfair_cleaned  525892 non-null  object\n",
      " 1   pplhlp_cleaned   527858 non-null  object\n",
      " 2   ppltrst_cleaned  528698 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.1+ MB\n",
      "None\n",
      "  pplfair_cleaned pplhlp_cleaned ppltrst_cleaned\n",
      "0               7              7               7\n",
      "1               3              0               6\n",
      "2               3              8               0\n",
      "3               5              7               8\n",
      "4               8              6               8\n"
     ]
    }
   ],
   "source": [
    "# Check the cleaned columns for missing values\n",
    "print(ess_reduced[['pplfair_cleaned', 'pplhlp_cleaned', 'ppltrst_cleaned']].info())\n",
    "\n",
    "# View a sample of the cleaned data\n",
    "print(ess_reduced[['pplfair_cleaned', 'pplhlp_cleaned', 'ppltrst_cleaned']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radio/TV usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for time-based variables\n",
    "# Each range is represented by the midpoint of the time range\n",
    "# Special values (66, 77, 88, 99) are treated as missing (None)\n",
    "time_mapping = {\n",
    "    0: 0,        # No time at all\n",
    "    1: 0.25,     # Less than 0.5 hour\n",
    "    2: 0.75,     # 0.5 hour to 1 hour\n",
    "    3: 1.25,     # More than 1 hour, up to 1.5 hours\n",
    "    4: 1.75,     # More than 1.5 hours, up to 2 hours\n",
    "    5: 2.25,     # More than 2 hours, up to 2.5 hours\n",
    "    6: 2.75,     # More than 2.5 hours, up to 3 hours\n",
    "    7: 3.5,      # More than 3 hours\n",
    "    66: None,    # Not applicable\n",
    "    77: None,    # Refusal\n",
    "    88: None,    # Don't know\n",
    "    99: None     # No answer\n",
    "}\n",
    "\n",
    "# Convert 'rdpol' to continuous data\n",
    "# This measures time spent on radio news/politics on an average weekday\n",
    "ess_reduced['rdpol_continuous'] = ess_reduced['rdpol'].map(time_mapping)\n",
    "\n",
    "# Convert 'rdtot' to continuous data\n",
    "# This measures total time spent on radio on an average weekday\n",
    "ess_reduced['rdtot_continuous'] = ess_reduced['rdtot'].map(time_mapping)\n",
    "\n",
    "# Convert 'tvpol' to continuous data\n",
    "# This measures time spent on TV news/politics on an average weekday\n",
    "ess_reduced['tvpol_continuous'] = ess_reduced['tvpol'].map(time_mapping)\n",
    "\n",
    "# Convert 'tvtot' to continuous data\n",
    "# This measures total time spent watching TV on an average weekday\n",
    "ess_reduced['tvtot_continuous'] = ess_reduced['tvtot'].map(time_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ability to participate in politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'cptppol' (Confidence in participating in politics)\n",
    "# Scale: 0 (Not confident) to 10 (Completely confident)\n",
    "# Replace special values (77: Refusal, 88: Don't know, 99: No answer) with None\n",
    "ess_reduced['cptppol_cleaned'] = ess_reduced['cptppol'].replace({\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None   # No answer\n",
    "})\n",
    "\n",
    "# Convert 'cptppola' (Simplified scale for confidence in politics) to continuous\n",
    "# Map values to midpoints for consistency in scaling\n",
    "cptppola_mapping = {\n",
    "    1: 0,      # Not at all confident\n",
    "    2: 2.5,    # A little confident\n",
    "    3: 5,      # Quite confident\n",
    "    4: 7.5,    # Very confident\n",
    "    5: 10,     # Completely confident\n",
    "    7: None,   # Refusal\n",
    "    8: None,   # Don't know\n",
    "    9: None    # No answer\n",
    "}\n",
    "ess_reduced['cptppola_continuous'] = ess_reduced['cptppola'].map(cptppola_mapping)\n",
    "\n",
    "# Clean 'dmcntov' (Perceived democracy in the country)\n",
    "# Scale: 0 (Not democratic) to 10 (Completely democratic)\n",
    "ess_reduced['dmcntov_cleaned'] = ess_reduced['dmcntov'].replace({\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None   # No answer\n",
    "})\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. lrscale: Placement on left-right scale\n",
    "\n",
    "    Numeric ordinal scale from 0 (Left) to 10 (Right).\n",
    "    Special values (77, 88, 99) should be replaced with None.\n",
    "\n",
    "b. polcmpl: Politics too complicated to understand\n",
    "\n",
    "    Numeric ordinal scale with values from 1 (Never) to 5 (Frequently).\n",
    "    Special values (7, 8, 9) should be replaced with None.\n",
    "\n",
    "\n",
    "c. polintr: How interested in politics\n",
    "\n",
    "    Numeric ordinal scale with values from 1 (Very interested) to 4 (Not at all interested).\n",
    "    Special values (7, 8, 9) should be replaced with None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for special missing values\n",
    "# These values indicate missing data and should be replaced with None\n",
    "missing_values_mapping = {\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None,  # No answer\n",
    "    7: None,   # Refusal (specific to 'polcmpl' and 'polintr')\n",
    "    8: None,   # Don't know\n",
    "    9: None    # No answer\n",
    "}\n",
    "\n",
    "# Clean 'lrscale' (Placement on left-right scale)\n",
    "# Scale: 0 (Left) to 10 (Right), with special values treated as missing\n",
    "ess_reduced['lrscale_cleaned'] = ess_reduced['lrscale'].replace(missing_values_mapping)\n",
    "\n",
    "# Clean 'polcmpl' (Politics too complicated to understand)\n",
    "# Scale: 1 (Never) to 5 (Frequently), with special values treated as missing\n",
    "ess_reduced['polcmpl_cleaned'] = ess_reduced['polcmpl'].replace(missing_values_mapping)\n",
    "\n",
    "# Clean 'polintr' (How interested in politics)\n",
    "# Scale: 1 (Very interested) to 4 (Not at all interested), with special values treated as missing\n",
    "ess_reduced['polintr_cleaned'] = ess_reduced['polintr'].replace(missing_values_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Politicians and political system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for simplified ordinal scales (psppipla, psppsgva)\n",
    "# Values are mapped to midpoints for consistency with broader scales\n",
    "simplified_scale_mapping = {\n",
    "    1: 0,      # Not at all\n",
    "    2: 2.5,    # Very little\n",
    "    3: 5,      # Some\n",
    "    4: 7.5,    # A lot\n",
    "    5: 10,     # A great deal\n",
    "    7: None,   # Refusal\n",
    "    8: None,   # Don't know\n",
    "    9: None    # No answer\n",
    "}\n",
    "\n",
    "# Clean 'psppipl' (Political system allows influence on politics)\n",
    "# Scale: 0 (Not at all) to 10 (Completely)\n",
    "ess_reduced['psppipl_cleaned'] = ess_reduced['psppipl'].replace({\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None   # No answer\n",
    "})\n",
    "\n",
    "# Clean 'psppsgv' (Political system allows a say in what government does)\n",
    "# Scale: 0 (Not at all) to 10 (Completely)\n",
    "ess_reduced['psppsgv_cleaned'] = ess_reduced['psppsgv'].replace({\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None   # No answer\n",
    "})\n",
    "\n",
    "# Clean 'ptcpplt' (Politicians care about public opinion)\n",
    "# Scale: 0 (Not at all) to 10 (Completely)\n",
    "ess_reduced['ptcpplt_cleaned'] = ess_reduced['ptcpplt'].replace({\n",
    "    77: None,  # Refusal\n",
    "    88: None,  # Don't know\n",
    "    99: None   # No answer\n",
    "})\n",
    "\n",
    "# Convert 'psppipla' (Influence on politics, simplified scale) to continuous\n",
    "ess_reduced['psppipla_continuous'] = ess_reduced['psppipla'].map(simplified_scale_mapping)\n",
    "\n",
    "# Convert 'psppsgva' (Say in government, simplified scale) to continuous\n",
    "ess_reduced['psppsgva_continuous'] = ess_reduced['psppsgva'].map(simplified_scale_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  psppipl_cleaned  psppipla_continuous psppsgv_cleaned  psppsgva_continuous  \\\n",
      "0             NaN                  NaN             NaN                  NaN   \n",
      "1             NaN                  NaN             NaN                  NaN   \n",
      "2             NaN                  NaN             NaN                  NaN   \n",
      "3             NaN                  NaN             NaN                  NaN   \n",
      "4             NaN                  NaN             NaN                  NaN   \n",
      "\n",
      "  ptcpplt_cleaned  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530711 entries, 0 to 530710\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   psppipl_cleaned      39279 non-null   object \n",
      " 1   psppipla_continuous  189902 non-null  float64\n",
      " 2   psppsgv_cleaned      39224 non-null   object \n",
      " 3   psppsgva_continuous  189408 non-null  float64\n",
      " 4   ptcpplt_cleaned      39557 non-null   object \n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 20.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the cleaned and transformed columns\n",
    "print(ess_reduced[['psppipl_cleaned', 'psppipla_continuous', 'psppsgv_cleaned', 'psppsgva_continuous', 'ptcpplt_cleaned']].head())\n",
    "\n",
    "# Check for missing values\n",
    "print(ess_reduced[['psppipl_cleaned', 'psppipla_continuous', 'psppsgv_cleaned', 'psppsgva_continuous', 'ptcpplt_cleaned']].info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satisfaction with everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special missing values (77, 88, 99) with None for satisfaction variables\n",
    "ess_reduced['stfdem_cleaned'] = ess_reduced['stfdem'].replace({77: None, 88: None, 99: None})\n",
    "ess_reduced['stfeco_cleaned'] = ess_reduced['stfeco'].replace({77: None, 88: None, 99: None})\n",
    "ess_reduced['stfgov_cleaned'] = ess_reduced['stfgov'].replace({77: None, 88: None, 99: None})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trust variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all follow the same scale: 0 (Not at all) to 10 (Completely) \n",
    "# so only cleaned and checked for missing values\n",
    "# Replace special missing values (77, 88, 99) with None for trust variables\n",
    "ess_reduced['trstep_cleaned'] = ess_reduced['trstep'].replace({77: None, 88: None, 99: None})\n",
    "ess_reduced['trstlgl_cleaned'] = ess_reduced['trstlgl'].replace({77: None, 88: None, 99: None})\n",
    "ess_reduced['trstplc_cleaned'] = ess_reduced['trstplc'].replace({77: None, 88: None, 99: None})\n",
    "ess_reduced['trstplt_cleaned'] = ess_reduced['trstplt'].replace({77: None, 88: None, 99: None})\n",
    "ess_reduced['trstprl_cleaned'] = ess_reduced['trstprl'].replace({77: None, 88: None, 99: None})\n",
    "ess_reduced['trstprt_cleaned'] = ess_reduced['trstprt'].replace({77: None, 88: None, 99: None})\n",
    "ess_reduced['trstun_cleaned'] = ess_reduced['trstun'].replace({77: None, 88: None, 99: None})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Composite score for overall trust in governments, combination of: trstlgl, trstplc, trstplt, trstprl, trstprt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an overall trust in national governments variable\n",
    "ess_reduced['overall_trust_national'] = ess_reduced[\n",
    "    ['trstlgl_cleaned', 'trstplc_cleaned', 'trstplt_cleaned', 'trstprl_cleaned', 'trstprt_cleaned']\n",
    "].mean(axis=1)\n",
    "\n",
    "# add the columns to the dataset\n",
    "ess_reduced['overall_trust_national'] = ess_reduced['overall_trust_national']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trstlgl_cleaned trstplc_cleaned trstplt_cleaned trstprl_cleaned  \\\n",
      "0              10              10               0               9   \n",
      "1               8               5               0               0   \n",
      "2               4               8               2               6   \n",
      "3              10               9               4               8   \n",
      "4               7               4               4               6   \n",
      "\n",
      "  trstprt_cleaned overall_trust_national  \n",
      "0             NaN                   7.25  \n",
      "1             NaN                   3.25  \n",
      "2             NaN                    5.0  \n",
      "3             NaN                   7.75  \n",
      "4             NaN                   5.25  \n"
     ]
    }
   ],
   "source": [
    "# check if the overall trust in national governments variable was added\n",
    "print(ess_reduced[['trstlgl_cleaned', 'trstplc_cleaned', 'trstplt_cleaned', 'trstprl_cleaned', 'trstprt_cleaned', 'overall_trust_national']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting habits and loyalty to government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'vote' (Voted in the last national election)\n",
    "# Categories: 1 (Yes), 2 (No), 3 (Not eligible to vote)\n",
    "# Special values (7: Refusal, 8: Don't know, 9: No answer) replaced with None\n",
    "ess_reduced['vote_cleaned'] = ess_reduced['vote'].replace({\n",
    "    3: None,  # Not eligible to vote\n",
    "    7: None,  # Refusal\n",
    "    8: None,  # Don't know\n",
    "    9: None   # No answer\n",
    "})\n",
    "\n",
    "# Clean 'loylead' (Loyalty towards leaders)\n",
    "# Categories: 1 (Agree strongly) to 5 (Disagree strongly)\n",
    "# Special values (7: Refusal, 8: Don't know, 9: No answer) replaced with None\n",
    "ess_reduced['loylead_cleaned'] = ess_reduced['loylead'].replace({\n",
    "    7: None,  # Refusal\n",
    "    8: None,  # Don't know\n",
    "    9: None   # No answer\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create country and year columns in the reduced dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   country    year\n",
      "0  Austria  2002.0\n",
      "1  Austria  2002.0\n",
      "2  Austria  2002.0\n",
      "3  Austria  2002.0\n",
      "4  Austria  2002.0\n"
     ]
    }
   ],
   "source": [
    "# Map country and year columns\n",
    "ess_reduced['country'] = ess_reduced['cntry'].map(ess_country_mapping)\n",
    "ess_reduced['year'] = ess_reduced['name'].map(ess_name_to_year)\n",
    "\n",
    "# Check if 'country' and 'year' columns are added\n",
    "print(ess_reduced[['country', 'year']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   country  year\n",
      "0  Austria  2002\n",
      "1  Austria  2002\n",
      "2  Austria  2002\n",
      "3  Austria  2002\n",
      "4  Austria  2002\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'year' is an integer and fill missing values with 0\n",
    "ess_reduced['year'] = ess_reduced['year'].fillna(ess_reduced['year'].mode()[0]).astype(int)\n",
    "\n",
    "# Verify the year column\n",
    "print(ess_reduced[['country', 'year']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all the answers in the ess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   country  essround  edition          idno   dweight  pspwght   pweight  \\\n",
      "0  Albania       6.0      2.6    628.335554  1.000000      1.0  0.186008   \n",
      "1  Austria       1.0      6.7   1977.049623  0.999998      1.0  0.271487   \n",
      "2  Austria       2.0      3.6   2201.447695  1.000017      1.0  0.302006   \n",
      "3  Austria       3.0      3.7   2738.014553  1.000005      1.0  0.289116   \n",
      "4  Austria      10.0      3.1  33847.528208  1.000000      1.0  0.381786   \n",
      "\n",
      "   anweight      prob    stratum  ...  nwsppol_continuous  nwsptot_continuous  \\\n",
      "0  0.186008       NaN        NaN  ...                 NaN                 NaN   \n",
      "1  0.271488       NaN        NaN  ...            0.420998            0.624833   \n",
      "2       NaN       NaN        NaN  ...            0.395964            0.613738   \n",
      "3       NaN       NaN        NaN  ...            0.431818            0.660326   \n",
      "4  0.381786  0.000839  59.987019  ...                 NaN                 NaN   \n",
      "\n",
      "   rdpol_continuous  rdtot_continuous  tvpol_continuous  tvtot_continuous  \\\n",
      "0               NaN               NaN          0.913601          2.078125   \n",
      "1          0.593638          1.651316          0.662666          1.643271   \n",
      "2          0.547958          1.593344          0.601188          1.717464   \n",
      "3          0.635711          1.689815          0.594678          1.708298   \n",
      "4               NaN               NaN               NaN               NaN   \n",
      "\n",
      "   cptppola_continuous  psppipla_continuous  psppsgva_continuous    year  \n",
      "0                  NaN                  NaN                  NaN  2012.0  \n",
      "1                  NaN                  NaN                  NaN  2002.0  \n",
      "2                  NaN                  NaN                  NaN  2004.0  \n",
      "3                  NaN                  NaN                  NaN  2006.0  \n",
      "4              4.46347             3.203676             3.205868  2008.0  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure numeric aggregation columns are correctly identified\n",
    "agg_columns = ess_reduced.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Group by 'country' and 'year' and calculate the mean for numeric columns\n",
    "ess_aggregated = ess_reduced.groupby(['country', 'year'], as_index=False)[agg_columns].mean()\n",
    "\n",
    "# Verify the result\n",
    "print(ess_aggregated.head())\n",
    "\n",
    "# Save the aggregated data to a new file\n",
    "ess_aggregated.to_csv(r\"C:\\Users\\belan\\bap_thesis\\data\\aggregated_ESS_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belan\\AppData\\Local\\Temp\\ipykernel_51916\\705827187.py:7: DtypeWarning: Columns (1240) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  vdem_filtered = pd.read_csv(vdem_filtered_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   country  essround  edition          idno   dweight  pspwght   pweight  \\\n",
      "0  Austria       1.0      6.7   1977.049623  0.999998      1.0  0.271487   \n",
      "1  Austria       2.0      3.6   2201.447695  1.000017      1.0  0.302006   \n",
      "2  Austria       3.0      3.7   2738.014553  1.000005      1.0  0.289116   \n",
      "3  Austria      10.0      3.1  33847.528208  1.000000      1.0  0.381786   \n",
      "4  Austria       7.0      2.3   1771.375487  1.000000      1.0  0.406019   \n",
      "\n",
      "   anweight      prob    stratum  ...  e_miurbani  e_pefeliex   e_wb_pop  \\\n",
      "0  0.271488       NaN        NaN  ...         NaN         NaN  8081957.0   \n",
      "1       NaN       NaN        NaN  ...         NaN         NaN  8171966.0   \n",
      "2       NaN       NaN        NaN  ...         NaN         NaN  8268641.0   \n",
      "3  0.381786  0.000839  59.987019  ...         NaN         NaN  8321496.0   \n",
      "4  0.406019       NaN        NaN  ...         NaN         NaN  8546356.0   \n",
      "\n",
      "   e_pechmor  e_miinteco  e_civil_war  e_miinterc  e_pt_coup  \\\n",
      "0       5.31         NaN          0.0         NaN        0.0   \n",
      "1       5.05         NaN          0.0         NaN        0.0   \n",
      "2       4.76         NaN          0.0         NaN        0.0   \n",
      "3       4.54         NaN          NaN         NaN        0.0   \n",
      "4       3.80         NaN          NaN         NaN        0.0   \n",
      "\n",
      "   e_pt_coup_attempts  overall_trust_national  \n",
      "0                 0.0                7.045968  \n",
      "1                 0.0                6.970035  \n",
      "2                 0.0                7.579044  \n",
      "3                 0.0                5.465502  \n",
      "4                 0.0                5.956992  \n",
      "\n",
      "[5 rows x 4667 columns]\n"
     ]
    }
   ],
   "source": [
    "# File paths for datasets\n",
    "ess_aggregated_path = r\"C:\\Users\\belan\\bap_thesis\\data\\aggregated_ESS_data.csv\"\n",
    "vdem_filtered_path = r\"C:\\Users\\belan\\bap_thesis\\data\\filtered_V-Dem_data.csv\"\n",
    "\n",
    "# Read the datasets\n",
    "ess_aggregated = pd.read_csv(ess_aggregated_path)\n",
    "vdem_filtered = pd.read_csv(vdem_filtered_path)\n",
    "\n",
    "# Extract the shared years and countries from the ESS dataset\n",
    "shared_years = ess_aggregated['year'].dropna().unique()\n",
    "shared_countries = ess_aggregated['country'].dropna().unique()\n",
    "\n",
    "# Filter the V-Dem dataset to include only these shared years and countries\n",
    "vdem_filtered_common = vdem_filtered[\n",
    "    (vdem_filtered['year'].isin(shared_years)) &\n",
    "    (vdem_filtered['country_name'].isin(shared_countries))\n",
    "]\n",
    "\n",
    "# Merge the datasets on 'year' and 'country'\n",
    "combined_data = pd.merge(\n",
    "    ess_aggregated, \n",
    "    vdem_filtered_common, \n",
    "    left_on=['year', 'country'], \n",
    "    right_on=['year', 'country_name'], \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Add 'overall_trust_national' column as the mean of the specified trust variables\n",
    "trust_columns = ['trstlgl', 'trstplc', 'trstplt', 'trstprl', 'trstprt']\n",
    "if all(col in combined_data.columns for col in trust_columns):  # Check if all trust columns exist\n",
    "    combined_data['overall_trust_national'] = combined_data[trust_columns].mean(axis=1, skipna=True)\n",
    "else:\n",
    "    print(\"Warning: One or more trust columns are missing in the merged dataset.\")\n",
    "\n",
    "# Display the first few rows of the combined dataset to verify\n",
    "print(combined_data.head())\n",
    "\n",
    "# Save the combined dataset\n",
    "combined_data.to_csv(r\"C:\\Users\\belan\\bap_thesis\\data\\combined_data_with_trust.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_assignment_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
